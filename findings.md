# ğŸ” Audit of Racial Bias in COMPAS Recidivism Risk Assessment System

---

## ğŸ“‹ Executive Summary

This audit analyzes the **COMPAS** (Correctional Offender Management Profiling for Alternative Sanctions) dataset using **IBM's AI Fairness 360 toolkit** to assess racial bias in recidivism risk predictions. The analysis reveals **significant racial disparities** that warrant immediate attention and remediation.

---

## ğŸš¨ Key Findings

### Critical Disparities in Error Rates

The audit uncovered **substantial racial bias** in COMPAS risk scores:

| Metric | Non-Caucasian | Caucasian | Difference |
|--------|---------------|-----------|-----------|
| **False Positive Rate (FPR)** | 0.234 | 0.161 | +45% â†‘ |
| **False Negative Rate (FNR)** | 0.299 | 0.312 | -4.2% â†“ |

**What this means:**
- Non-Caucasian defendants are **45% more likely** to be incorrectly labeled as high-risk when they do not reoffend
- Caucasian defendants are more likely to be incorrectly classified as low-risk when they do reoffend

### Fairness Metrics

- **Disparate Impact Ratio:** 0.68 (âš ï¸ **BELOW** the 0.80 acceptable threshold)
- **Statistical Parity Difference:** -0.098 (confirms systematic bias in risk score distributions)

---

## ğŸ”¬ Root Causes

The bias likely stems from multiple interconnected factors:

1. **Historical Arrest Patterns** - Biased historical data embedded in the training dataset
2. **Socioeconomic Correlations** - Race-correlated socioeconomic variables the model captures indirectly
3. **Proxy Features** - Feature selection that indirectly proxies for race
4. **Model Behavior** - Algorithm systematically over-predicts risk for non-Caucasian defendants and under-predicts for Caucasian defendants

---

## âœ… Remediation Recommendations

### 1. **Pre-processing** ğŸ“Š
Implement reweighting techniques to balance training data across racial groups, as demonstrated in our mitigation analysis which improved statistical parity.

### 2. **In-processing** âš™ï¸
Develop fair-aware algorithms that explicitly optimize for **both accuracy AND fairness** during model training.

### 3. **Post-processing** ğŸ¯
Apply threshold adjustment techniques to equalize error rates across demographic groups.

### 4. **Transparency** ğŸ“–
Enhance model interpretability and provide clear documentation of limitations and potential biases.

### 5. **Continuous Monitoring** ğŸ“ˆ
Establish ongoing bias auditing protocols and regular model performance assessments across demographic subgroups.

---

## ğŸ“Œ Conclusion

The COMPAS system demonstrates **significant racial bias** that could lead to unfair outcomes in criminal justice decisions. **Immediate remediation efforts** should focus on implementing fairness-aware machine learning techniques while maintaining model performance standards.

